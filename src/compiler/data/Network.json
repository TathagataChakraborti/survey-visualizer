{
    "nodes": [
        {
            "UID": 18,
            "slug": "mbp-plex",
            "title": "Autonomous Learning of Action Models for Planning",
            "abstract": "This paper introduces two new frameworks for learning action models for planning. In the mistake-bounded planning framework, the learner has access to a planner for the given model representation, a simulator, and a planning problem generator, and aims to learn a model with at most a polynomial number of faulty plans. In the planned exploration framework, the learner does not have access to a problem generator and must instead design its own problems, plan for them, and converge with at most a polynomial number of planning attempts. The paper reduces learning in these frameworks to concept learning with one-sided error and provides algorithms for successful learning in both frameworks. A specific family of hypothesis spaces is shown to be efficiently learnable in both the frameworks.\n\n",
            "link": "https://papers.nips.cc/paper/2011/file/4671aeaf49c792689533b00664a5c3ef-Paper.pdf",
            "authors": "Mehta, Neville, Prasad Tadepalli, and Alan Fern",
            "venue": "NeurIPS",
            "sessions": null,
            "year": 2011,
            "keywords": null,
            "tags": [],
            "citations": [],
            "selected": true
        },
        {
            "UID": 19,
            "slug": "kira",
            "title": "Learning STRIPS Operators from Noisy and Incomplete Observations",
            "abstract": "Agents learning to act autonomously in real-world domains must acquire a model of the dynamics of the domain in which they operate. Learning domain dynamics can be challenging, especially where an agent only has partial access to the world state, and/or noisy external sensors. Even in standard STRIPS domains, existing approaches cannot learn from noisy, incomplete observations typical of real-world domains. We propose a method which learns STRIPS action models in such domains, by decomposing the problem into first learning a transition function between states in the form of a set of classifiers, and then deriving explicit STRIPS rules from the classifiers' parameters. We evaluate our approach on simulated standard planning domains from the International Planning Competition, and show that it learns useful domain descriptions from noisy, incomplete observations.\n",
            "link": "https://arxiv.org/abs/1210.4889",
            "authors": "Mourao, Kira, Luke S. Zettlemoyer, Ronald Petrick, and Mark Steedman",
            "venue": "UAI",
            "sessions": null,
            "year": 2012,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Partially Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Noise",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Predicate Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Action Information"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Parameters Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Preconditions",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Effects ",
                    "parent": "Action Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 26,
            "slug": "cpisa",
            "title": "Robust planning with incomplete domain models",
            "abstract": "Most current planners assume complete domain models and focus on generating correct plans. Unfortunately, domain modeling is a laborious and error-prone task, thus real world agents have to plan with incomplete domain models. While domain experts cannot guarantee completeness, often they are able to circumscribe the incompleteness of the model by providing annotations as to which parts of the domain model may be incomplete. In this paper, we study planning problems with incomplete domain models where the annotations specify possible preconditions and effects of actions. We show that the problem of assessing the quality of a plan, or its plan robustness, is #P-complete, establishing its equivalence with the weighted model counting problems. We present two approaches to synthesizing robust plans. While the method based on the compilation to conformant probabilistic planning is much intuitive, its performance appears to be limited to only small problem instances. Our second approach based on stochastic heuristic search works well for much larger problems. It aims to use the robustness measure directly for estimating heuristic distance, which is then used to guide the search. Our planning system, PISA, outperforms a state-of-the-art planner handling incomplete domain models in most of the tested domains, both in terms of plan quality and planning time. Finally, we also present an extension of PISA called CPISA that is able to exploit the available of past successful plan traces to both improve the robustness of the synthesized plans and reduce the domain modeling burden.\n\n",
            "link": "https://www.sciencedirect.com/science/article/pii/S0004370216301539",
            "authors": "Nguyen, Tuan, Sarath Sreedharan, and Subbarao Kambhampati",
            "venue": "AIJ",
            "sessions": null,
            "year": 2017,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Typing",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Parameters Typed",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Unobservable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Predicate Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Typing",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Action Information"
                },
                {
                    "name": "Typing",
                    "parent": "Action Information"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Parameters Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Preconditions",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Effects ",
                    "parent": "Action Information"
                },
                {
                    "name": "State Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Goal Access",
                    "parent": "State Information"
                },
                {
                    "name": "Init Access",
                    "parent": "State Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 47,
            "slug": "konidaris-aaai",
            "title": "Constructing Symbolic Representations for High-Level Planning",
            "abstract": "We consider the problem of constructing a symbolic description of a continuous, low-level environment for use in planning. We show that symbols that can represent the preconditions and effects of an agent's actions are both necessary and sufficient for high-level planning. This eliminates the symbol design problem when a representation must be constructed in advance, and in principle enables an agent to autonomously learn its own symbolic representations. The resulting representation can be converted into PDDL, a canonical high-level planning representation that enables very fast planning.\n",
            "link": "http://irl.cs.brown.edu/pubs/orig_sym_aaai.pdf",
            "authors": "Konidaris, George, Leslie Kaelbling, and Tomas Lozano-Perez",
            "venue": "AAAI",
            "sessions": null,
            "year": 2014,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Fully Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "State Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Init Access",
                    "parent": "State Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 48,
            "slug": "konidaris-ijcai",
            "title": "Symbol Acquisition for Probabilistic High-Level Planning",
            "abstract": "We introduce a framework that enables an agent to autonomously learn its own symbolic representation of a low-level, continuous environment. Propositional symbols are formalized as names for probability distributions, providing a natural means of dealing with uncertain representations and probabilistic plans. We determine the symbols that are sufficient for computing the probability with which a plan will succeed, and demonstrate the acquisition of a symbolic representation in a computer game domain.\n",
            "link": "https://cs.brown.edu/people/gdk/pubs/sym-prob.pdf",
            "authors": "Konidaris, George, Leslie Kaelbling, and Tomas Lozano-Perez",
            "venue": "IJCAI",
            "sessions": null,
            "year": 2015,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Probabilistic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Cost",
                    "parent": "Actions"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Fully Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Cost",
                    "parent": "Action Information"
                },
                {
                    "name": "State Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Init Access",
                    "parent": "State Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                },
                {
                    "name": "Cost",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 34,
            "slug": "blai",
            "title": "Learning First-Order Symbolic Representations for Planning from the Structure of the State Space",
            "abstract": "One of the main obstacles for developing flexible AI systems is the split between data-based learners and model-based solvers. Solvers such as classical planners are very flexible and can deal with a variety of problem instances and goals but require first-order symbolic models. Data-based learners, on the other hand, are robust but do not produce such representations. In this work we address this split by showing how the first-order symbolic representations that are used by planners can be learned from non-symbolic inputs that encode the structure of the state space. The representation learning problem is formulated as the problem of inferring planning instances over a common but unknown first-order domain that account for the structure of the observed state space. This means to infer a complete first-order representation (i.e. general action schemas, relational symbols, and objects) that explains the observed state space structures. The inference problem is cast as a two-level combinatorial search where the outer level searches for values of a small set of hyperparameters and the inner level, solved via SAT, searches for a first-order symbolic model. The framework is shown to produce general and correct first-order representations for standard problems like Gripper, Blocksworld, and Hanoi from input graphs that encode the flat state-space structure of a single instance.\n",
            "link": "https://arxiv.org/abs/1909.05546",
            "authors": "Bonet, Blai, and Hector Geffner",
            "venue": "ECAI",
            "sessions": null,
            "year": 2020,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Unobservable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 24,
            "slug": "lop",
            "title": "Domain Model Acquisition in the Presence of Static Relations in the LOP System",
            "abstract": "This paper addresses the problem of domain model acquisition from only action traces when the underlying domain model contains static relations. Domain model acquisition is the problem of synthesising a planning domain model from example plan traces and potentially other information, such as intermediate states. The LOCM and LOCMII domain model acquisition systems are highly effective at determining the dynamics of domain models with only plan traces as input (i.e. they do not rely on extra inputs such as predicate definitions, initial, final and intermediate states or invariants). Much of the power of the LOCM family of algorithms comes from the assumption that each action parameter goes through a transition. One place that this assumption is too strong is in the case of static predicates. We present a new domain model acquisition algorithm, LOP, that induces static predicates by using a combination of the generalised output from LOCM2 and a set of optimal plans as input to the learning system. We observe that static predicates can be seen as restrictions on the valid groundings of actions. Without the static predicates restricting possible groundings, the domains induced by LOCMII produce plans that are typically shorter than the true optimal solutions. LOP works by finding a minimal static predicate for each operator that preserves the length of the optimal plan.\n\n",
            "link": "https://www.ijcai.org/Proceedings/16/Papers/622.pdf",
            "authors": "Gregory, Peter, and Stephen Cresswell",
            "venue": "IJCAI",
            "sessions": null,
            "year": 2016,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Agent Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Rationality",
                    "parent": "Agent Features"
                },
                {
                    "name": "Optimally Rational",
                    "parent": "Rationality"
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Typing",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Parameters Typed",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Unobservable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Action Information"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Parameters Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 44,
            "slug": "samplus",
            "title": "Learning Probably Approximately Complete and Safe Action Models for Stochastic Worlds",
            "abstract": "We consider the problem of learning action models for planning in stochastic, unknown, environments, that can be defined using the Probabilistic Planning Domain Description Language (PPDDL). As input, we are given set of previously executed trajectories, and the main challenge is to learn an action model that has a similar goal achievement probability to the policies used to create these trajectories. To this end, we introduce a variant of PPDDL in which there is uncertainty about the transition probabilities, specified by an interval for each factor that contains the respective true transition probabilities. Then, we present SAM+, an algorithm that learns such an imprecise-PPDDL environment model. SAM+ has a polynomial time and sample complexity, and guarantees that with high probability, the true environment is indeed captured by the defined intervals. We prove that the action model SAM+ outputs has a goal achievement probability that is almost as good or better than that of the policies used to produced the training trajectories. Then, we show how to produce a PPDDL model based on this imprecise-PPDDL that has similar properties.",
            "link": "https://www.aaai.org/AAAI22Papers/AAAI-6194.JubaB.pdf",
            "authors": "Juba, Brendan, and Roni Stern",
            "venue": "AAAI",
            "sessions": null,
            "year": 2022,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Probabilistic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Fully Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Predicate Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Action Information"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 25,
            "slug": "stern",
            "title": "Efficient, Safe, and Probably Approximately Complete Learning of Action Models",
            "abstract": "In this paper we explore the theoretical boundaries of planning in a setting where no model of the agent's actions is given. Instead of an action model, a set of successfully executed plans are given and the task is to generate a plan that is safe, i.e., guaranteed to achieve the goal without failing. To this end, we show how to learn a conservative model of the world in which actions are guaranteed to be applicable. This conservative model is then given to an off-the-shelf classical planner, resulting in a plan that is guaranteed to achieve the goal. However, this reduction from a model-free planning to a model-based planning is not complete: in some cases a plan will not be found even when such exists. We analyze the relation between the number of observed plans and the likelihood that our conservative approach will indeed fail to solve a solvable problem. Our analysis show that the number of trajectories needed scales gracefully.\n",
            "link": "https://arxiv.org/abs/1705.08961",
            "authors": "Stern, Roni, and Brendan Juba",
            "venue": "IJCAI",
            "sessions": null,
            "year": 2017,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Fully Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 15,
            "slug": "locm",
            "title": "Acquisition of Object-Centred Domain Models from Planning Examples",
            "abstract": "The problem of formulating knowledge bases containing ac- tion schema is a central concern in knowledge engineering for AI Planning. This paper describes LOCM, a system which carries out the automated induction of action schema from sets of example plans. Each plan is assumed to be a sound sequence of actions; each action in a plan is stated as a name and a list of objects that the action refers to. LOCM exploits the assumption that actions change the state of objects, and require objects to be in a certain state before they can be ex- ecuted. The novelty of LOCM is that it can induce action schema without being provided with any information about predicates or initial, goal or intermediate state descriptions for the example action sequences. In this paper we describe the implemented LOCM algorithm, and analyse its perfor- mance by its application to the induction of domain models for several domains. To evaluate the algorithm, we used ran- dom action sequences from existing models of domains, as well as solutions to past IPC problems.\n",
            "link": "https://ojs.aaai.org/index.php/ICAPS/article/view/13391",
            "authors": "Cresswell, Stephen, Thomas Leo McCluskey, and Margaret West",
            "venue": "ICAPS",
            "sessions": null,
            "year": 2009,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Typing",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Parameters Typed",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Unobservable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Action Information"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Parameters Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 10,
            "slug": "arms",
            "title": "Learning Action Models from Plan Examples with Incomplete Knowledge",
            "abstract": "AI planning requires the definition of an action model using a language such as PDDL as input. However, building an action model from scratch is a difficult and time-consuming task even for experts. In this paper, we develop an algorithm called ARMS for automatically discovering action models from a set of successful plan examples. Unlike the previous work in action-model learning, we do not assume complete knowledge of states in the middle of the example plans; that is, we assume that no intermediate states are given. This requirement is motivated by a variety of applications, including object tracking and plan monitoring where the knowledge about intermediate states is either minimal or unavailable to the observing agent. In a real world application, the cost is prohibitively high in labelling the training examples by manually annotating every state in a plan example from snapshots of an environment. To learn action models, our ARMS algorithm gathers knowledge on the statistical distribution of frequent sets of actions in the example plans. It then builds a propositional satisfiability (SAT) problem and solves it using a SAT solver. We lay the theoretical foundations of the learning problem and evaluate the effectiveness of ARMS empirically.\n\n",
            "link": "https://www.aaai.org/Papers/ICAPS/2005/ICAPS05-025.pdf",
            "authors": "Yang, Qiang, Kangheng Wu, and Yunfei Jiang",
            "venue": "ICAPS",
            "sessions": null,
            "year": 2005,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Typing",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Parameters Typed",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Partially Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Predicate Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Action Information"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Parameters Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Preconditions",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Effects ",
                    "parent": "Action Information"
                },
                {
                    "name": "State Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Goal Access",
                    "parent": "State Information"
                },
                {
                    "name": "Init Access",
                    "parent": "State Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Partial",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 38,
            "slug": "sam",
            "title": "Safe Learning of Lifted Action Models",
            "abstract": "Creating a domain model, even for classical, domain-independent planning, is a notoriously hard knowledge-engineering task. A natural approach to solve this problem is to learn a domain model from observations. However, model learning approaches frequently do not provide safety guarantees: the learned model may assume actions are applicable when they are not, and may incorrectly capture actions' effects. This may result in generating plans that will fail when executed. In some domains such failures are not acceptable, due to the cost of failure or inability to replan online after failure. In such settings, all learning must be done offline, based on some observations collected, e.g., by some other agents or a human. Through this learning, the task is to generate a plan that is guaranteed to be successful. This is called the model-free planning problem. Prior work proposed an algorithm for solving the model-free planning problem in classical planning. However, they were limited to learning grounded domains, and thus they could not scale. We generalize this prior work and propose the first safe model-free planning algorithm for lifted domains. We prove the correctness of our approach, and provide a statistical analysis showing that the number of trajectories needed to solve future problems with high probability is linear in the potential size of the domain model. We also present experiments on twelve IPC domains showing that our approach is able to learn the real action model in all cases with at most two trajectories.",
            "link": "https://arxiv.org/pdf/2107.04169.pdf",
            "authors": "Juba, Brendan, Hai S. Le, and Roni Stern",
            "venue": "KR",
            "sessions": null,
            "year": 2021,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Fully Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Predicate Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Action Information"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 40,
            "slug": "rim",
            "title": "Refining Incomplete Planning Domain Models Through Plan Traces",
            "abstract": "Most existing work on learning planning models assumes that the entire model needs to be learned from scratch. A more realistic situation is that the planning agent has an incomplete model which it needs to refine through learning. In this paper we propose and evaluate a method for doing this. Our method takes as input an incomplete model (with missing preconditions and effects in the actions), as well as a set of plan traces that are known to be correct. It outputs a \"refined\" model that not only captures additional precondition/effect knowledge about the given actions, but also \"macro actions\". We use a MAX-SAT framework for learning, where the constraints are derived from the executability of the given plan traces, as well as the preconditions/ effects of the given incomplete model. Unlike traditional macro-action learners which use macros to increase the efficiency of planning (in the context of a complete model), our motivation for learning macros is to increase the accuracy (robustness) of the plans generated with the refined model. We demonstrate the effectiveness of our approach through a systematic empirical evaluation.",
            "link": "https://rakaposhi.eas.asu.edu/camera-macro.pdf",
            "authors": "Zhuo, Hankz Hankui, Tuan Nguyen, and Subbarao Kambhampati",
            "venue": "IJCAI",
            "sessions": null,
            "year": 2013,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Typing",
                    "parent": "Actions"
                },
                {
                    "name": "Macros",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Parameters Typed",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Unobservable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Predicate Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Typing",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Action Information"
                },
                {
                    "name": "Typing",
                    "parent": "Action Information"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Parameters Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Preconditions",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Effects ",
                    "parent": "Action Information"
                },
                {
                    "name": "State Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Goal Access",
                    "parent": "State Information"
                },
                {
                    "name": "Init Access",
                    "parent": "State Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 20,
            "slug": "aman",
            "title": "Action-Model Acquisition from Noisy Plan Traces",
            "abstract": "There is increasing awareness in the planning community that the burden of specifying complete domain models is too high, which impedes the applicability of planning technology in many real-world domains. Although there have been many learning approaches that help automatically creating domain models, they all assume plan traces (training data) are correct. In this paper, we aim to remove this assumption, allowing plan traces to be with noise. Compared to collecting large amount of correct plan traces, it is much easier to collect noisy plan traces, e.g., we can directly exploit sensors to help collect noisy plan traces. We consider a novel solution for this challenge that can learn action models from noisy plan traces. We create a set of random variables to capture the possible correct plan traces behind the observed noisy ones, and build a graphical model to describe the physics of the domain. We then learn the parameters of the graphical model and acquire the domain model based on the learnt parameters. In the experiment, we empirically show that our approach is effective in several planning domains.\n\n",
            "link": "http://rakaposhi.eas.asu.edu/camera-noise.pdf",
            "authors": "Zhuo, Hankz Hankui, and Subbarao Kambhampati",
            "venue": "IJCAI",
            "sessions": null,
            "year": 2013,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Fully Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Predicate Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Action Information"
                },
                {
                    "name": "Noise",
                    "parent": "Action Information"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Parameters Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 42,
            "slug": "olam",
            "title": "Online Learning of Action Models for PDDL Planning",
            "abstract": "The automated learning of action models is widely recognised as a key and compelling challenge to address the difficulties of the manual specification of planning domains. Most state-of-the-art methods perform this learning offline from an input set of plan traces generated by the execution of (successful) plans. However, how to generate informative plan traces for learning action models is still an open issue. Moreover, plan traces might not be available for a new environment. In this paper, we propose an algorithm for learning action models online, incrementally during the execution of plans. Such plans are generated to achieve goals that the algorithm decides online in order to obtain informative plan traces and reach states from which useful information can be learned. We show some fundamental theoretical properties of the algorithm, and we experimentally evaluate the online learning of the action models over a large set of IPC domains.",
            "link": "https://www.ijcai.org/proceedings/2021/0566.pdf",
            "authors": "Leonardo Lamanna, Alessandro Saetti, Luciano Serafini, Alfonso Gerevini, Paolo Traverso\n",
            "venue": "IJCAI",
            "sessions": null,
            "year": 2021,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Fully Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Predicate Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Action Information"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Parameters Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Preconditions",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Effects ",
                    "parent": "Action Information"
                },
                {
                    "name": "State Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Goal Access",
                    "parent": "State Information"
                },
                {
                    "name": "Init Access",
                    "parent": "State Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 36,
            "slug": "aia",
            "title": "Asking the Right Questions: Learning Interpretable Action Models Through Query Answering",
            "abstract": "This paper develops a new approach for estimating an interpretable, relational model of a black-box autonomous agent that can plan and act. Our main contributions are a new paradigm for estimating such models using a minimal query interface with the agent, and a hierarchical querying algorithm that generates an interrogation policy for estimating the agent's internal model in a vocabulary provided by the user. Empirical evaluation of our approach shows that despite the intractable search space of possible agent models, our approach allows correct and scalable estimation of interpretable agent models for a wide class of black-box autonomous agents. Our results also show that this approach can use predicate classifiers to learn interpretable models of planning agents that represent states as images.\n",
            "link": "https://aair-lab.github.io/Publications/vms_aaai21.pdf",
            "authors": "Verma, Pulkit, Shashank Rao Marpally, and Siddharth Srivastava",
            "venue": "AAAI",
            "sessions": null,
            "year": 2021,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Fully Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Predicate Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Action Information"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Parameters Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Preconditions",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Effects ",
                    "parent": "Action Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 28,
            "slug": "diego",
            "title": "Learning STRIPS Action Models with Classical Planning",
            "abstract": "This paper presents a novel approach for learning STRIPS action models from examples that compiles this inductive learning task into a classical planning task. Interestingly, the compilation approach is flexible to different amounts of available input knowledge; the learning examples can range from a set of plans (with their corresponding initial and final states) to just a pair of initial and final states (no intermediate action or state is given). Moreover, the compilation accepts partially specified action models and it can be used to validate whether the observation of a plan execution follows a given STRIPS action model, even if this model is not fully specified.\n",
            "link": "https://arxiv.org/abs/1903.01153",
            "authors": "Aineto, Diego, Sergio Jim\u00e9nez, and Eva Onaindia",
            "venue": "ICAPS",
            "sessions": null,
            "year": 2018,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Partially Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Predicate Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Action Information"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Parameters Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Preconditions",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Effects ",
                    "parent": "Action Information"
                },
                {
                    "name": "State Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Goal Access",
                    "parent": "State Information"
                },
                {
                    "name": "Init Access",
                    "parent": "State Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Partial",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 7,
            "slug": "observer",
            "title": "Learning Planning Operators by Observation and Practice",
            "abstract": "The work described in this paper addresses learning planning operators by observing expert agents and subsequent knowledge refinement in a learning-by-doing paradigm. The observations of the expert agent consist of: 1) the sequence of actions being executed, 2) the state in which each action is executed, and 3) the state resulting from the execution of each action. Planning operators are learned from these observation sequences in an incremental fashion utilizing a conservative specific-to-general inductive generalization process. In order to refine the new operators to make them correct and complete, the system uses the new operators to solve practice problems, analyzing and learning from the execution traces of the resulting solutions or execution failures. We describe techniques for planning and plan repair with incorrect and incomplete domain knowledge, and for operator refinement through a process which integrates planning, execution, and plan repair. Our learning method is implemented on top of the PRODIGY architecture(Carbonell, Knoblock, & Minton 1990; Carbonell et al. 1992) and is demonstrated in the extended-strips domain (Minton 1988) and a subset the process planning domain(Gil 1991).",
            "link": "https://aaai.org/Papers/AIPS/1994/AIPS94-057.pdf",
            "authors": "Xuemei Wang",
            "venue": "AIPS",
            "sessions": null,
            "year": 1994,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Typing",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Parameters Typed",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Fully Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Preconditions",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Effects ",
                    "parent": "Action Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Partial",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 12,
            "slug": "arms",
            "title": "Learning action models from plan examples using weighted MAX-SAT",
            "abstract": "AI planning requires the definition of action models using a formal action and plan description language, such as the standard Planning Domain Definition Language (PDDL), as input. However, building action models from scratch is a difficult and time-consuming task, even for experts. In this paper, we develop an algorithm called ARMS (action-relation modelling system) for automatically discovering action models from a set of successful observed plans. Unlike the previous work in action-model learning, we do not assume complete knowledge of states in the middle of observed plans. In fact, our approach works when no or partial intermediate states are given. These example plans are obtained by an observation agent who does not know the logical encoding of the actions and the full state information between the actions. In a real world application, the cost is prohibitively high in labelling the training examples by manually annotating every state in a plan example from snapshots of an environment. To learn action models, ARMS gathers knowledge on the statistical distribution of frequent sets of actions in the example plans. It then builds a weighted propositional satisfiability (weighted MAX-SAT) problem and solves it using a MAX-SAT solver. We lay the theoretical foundations of the learning problem and evaluate the effectiveness of ARMS empirically.\n\n",
            "link": "https://www.sciencedirect.com/science/article/pii/S0004370206001408",
            "authors": "Yang, Qiang, Kangheng Wu, and Yunfei Jiang",
            "venue": "AIJ",
            "sessions": null,
            "year": 2007,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Typing",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Parameters Typed",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Partially Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Predicate Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Action Information"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Parameters Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Preconditions",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Effects ",
                    "parent": "Action Information"
                },
                {
                    "name": "State Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Goal Access",
                    "parent": "State Information"
                },
                {
                    "name": "Init Access",
                    "parent": "State Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Partial",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 41,
            "slug": "opmaker",
            "title": "An interactive method of inducing operator descriptions",
            "abstract": "Specifying operator descriptions for planning domain models, especially using standard pre- and post condition symbolism, is a slow and painstaking process. This is because one is trying to capture what is essentially procedural knowledge in a declarative way in a language whose design is influenced by the construction of planning engines. The problem is acute if nonplanning experts are undertaking this task, and/or the operators are complex or hierarchical. In this paper we describe opmaker, a method in which the domain expert specifies the declarative structure of the domain (in terms of an object hierarchy, object descriptions etc) and provides training operator sequences. This input is made in the context of a tools environment supporting planner domain acquisition and modelling. opmaker then induces a set of parameterised operator descriptions from these examples, removing the need for the user to become involved in complex parameter manipulation within the underlying symbolic, logicbased language. We discuss the empirical evaluation of the implemented induction algorithm with the help of a range of domains, and draw conclusions for future work.\n",
            "link": "http://eprints.hud.ac.uk/id/eprint/2516/",
            "authors": "McCluskey, Thomas Leo, N. Elisabeth Richardson, and Ron M. Simpson.",
            "venue": "AAAI",
            "sessions": null,
            "year": 2002,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Typing",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Parameters Typed",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Fully Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Predicate Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Typing",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Action Information"
                },
                {
                    "name": "Typing",
                    "parent": "Action Information"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Parameters Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Preconditions",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Effects ",
                    "parent": "Action Information"
                },
                {
                    "name": "State Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Goal Access",
                    "parent": "State Information"
                },
                {
                    "name": "Init Access",
                    "parent": "State Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 46,
            "slug": "andersen",
            "title": "Active Exploration for Learning Symbolic Representations",
            "abstract": "We introduce an online active exploration algorithm for data-efficiently learning an abstract symbolic model of an environment. Our algorithm is divided into two parts: the first part quickly generates an intermediate Bayesian symbolic model from the data that the agent has collected so far, which the agent can then use along with the second part to guide its future exploration towards regions of the state space that the model is uncertain about. We show that our algorithm outperforms random and greedy exploration policies on two different computer game domains. The first domain is an Asteroids-inspired game with complex dynamics but basic logical structure. The second is the Treasure Game, with simpler dynamics but more complex logical structure.",
            "link": "https://arxiv.org/abs/1709.01490",
            "authors": "Andersen, Garrett, and George Konidaris",
            "venue": "arXiv",
            "sessions": null,
            "year": 2017,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Probabilistic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Fully Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Noise",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Cost",
                    "parent": "Action Information"
                },
                {
                    "name": "State Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Init Access",
                    "parent": "State Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                },
                {
                    "name": "Cost",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 45,
            "slug": "konidaris",
            "title": "From skills to symbols: learning symbolic representations for abstract high-level planning",
            "abstract": "We consider the problem of constructing abstract representations for planning in high-dimensional, continuous environments. We assume an agent equipped with a collection of high-level actions, and construct representations provably capable of evaluating plans composed of sequences of those actions. We first consider the deterministic planning case, and show that the relevant computation involves set operations performed over sets of states. We define the specific collection of sets that is necessary and sufficient for planning, and use them to construct a grounded abstract symbolic representation that is provably suitable for deterministic planning. The resulting representation can be expressed in PDDL, a canonical high-level planning domain language; we construct such a representation for the Playroom domain and solve it in milliseconds using an off-the-shelf planner. We then consider probabilistic planning, which we show requires generalizing from sets of states to distributions over states. We identify the specific distributions required for planning, and use them to construct a grounded abstract symbolic representation that correctly estimates the expected reward and probability of success of any plan. In addition, we show that learning the relevant probability distributions corresponds to specific instances of probabilistic density estimation and probabilistic classification. We construct an agent that autonomously learns the correct abstract representation of a computer game domain, and rapidly solves it. Finally, we apply these techniques to create a physical robot system that autonomously learns its own symbolic representation of a mobile manipulation task directly from sensorimotor data---point clouds, map locations, and joint angles---and then plans using that representation. Together, these results establish a principled link between high-level actions and abstract representations, a concrete theoretical foundation for constructing abstract representations with provable properties, and a practical mechanism for autonomously learning abstract high-level representations.",
            "link": "https://cs.brown.edu/people/gdk/pubs/orig_sym_jair.pdf",
            "authors": "Konidaris, George, Leslie Pack Kaelbling, and Tomas Lozano-Perez.",
            "venue": "JAIR",
            "sessions": null,
            "year": 2018,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Probabilistic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Cost",
                    "parent": "Actions"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Partially Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Noise",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Cost",
                    "parent": "Action Information"
                },
                {
                    "name": "State Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Init Access",
                    "parent": "State Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                },
                {
                    "name": "Cost",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 31,
            "slug": "amdn",
            "title": "Learning Action Models from Plan Traces with Disordered Actions, Parallel\nActions, Noisy States",
            "abstract": "There is increasing awareness in the planning community that the burden of specifying complete domain models is too high, which impedes the applicability of planning technology in many real-world domains. Although there have many learning systems that help automatically learning domain models, most existing work assumes that the input traces are completely correct. A more realistic situation is that the plan traces are disordered and noisy, such as plan traces described by natural language. In this paper we propose and evaluate an approach for doing this. Our approach takes as input a set of plan traces with disordered actions and noise and outputs action models that can best explain the plan traces. We use a MAX-SAT framework for learning, where the constraints are derived from the given plan traces. Unlike traditional action models learners, the states in plan traces can be partially observable and noisy as well as the actions in plan traces can be disordered and parallel. We demonstrate the effectiveness of our approach through a systematic empirical evaluation with both IPC domains and the real-world dataset extracted from natural language documents.\n",
            "link": "https://arxiv.org/abs/1908.09800",
            "authors": "Zhuo, Hankz Hankui, Jing Peng, and Subbarao Kambhampati",
            "venue": "arXiv",
            "sessions": null,
            "year": 2019,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Partially Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Noise",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Predicate Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Action Information"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Parameters Known",
                    "parent": "Action Information"
                },
                {
                    "name": "State Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Goal Access",
                    "parent": "State Information"
                },
                {
                    "name": "Init Access",
                    "parent": "State Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 35,
            "slug": "dup-max",
            "title": "Discovering Underlying Plans Based on Shallow Models",
            "abstract": "Plan recognition aims to discover target plans (i.e., sequences of actions) behind observed actions, with history plan libraries or action models in hand. Previous approaches either discover plans by maximally \u201cmatching\u201d observed actions to plan libraries, assuming target plans are from plan libraries, or infer plans by executing action models to best explain the observed actions, assuming that complete action models are available. In real-world applications, however, target plans are often not from plan libraries, and complete action models are often not available, since building complete sets of plans and complete action models are often difficult or expensive. In this article, we view plan libraries as corpora and learn vector representations of actions using the corpora; we then discover target plans based on the vector representations. Specifically, we propose two approaches, DUP and RNNPlanner, to discover target plans based on vector representations of actions. DUP explores the EM-style (Expectation Maximization) framework to capture local contexts of actions and discover target plans by optimizing the probability of target plans, while RNNPlanner aims to leverage long-short term contexts of actions based on RNNs (Recurrent Neural Networks) framework to help recognize target plans. In the experiments, we empirically show that our approaches are capable of discovering underlying plans that are not from plan libraries without requiring action models provided. We demonstrate the effectiveness of our approaches by comparing its performance to traditional plan recognition approaches in three planning domains. We also compare DUP and RNNPlanner to see their advantages and disadvantages.\n\n",
            "link": "https://dl.acm.org/doi/abs/10.1145/3368270",
            "authors": "Zhuo, Hankz Hankui, Yantian Zha, Subbarao Kambhampati, and Xin Tian",
            "venue": "ACM TIST",
            "sessions": null,
            "year": 2020,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Unobservable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 9,
            "slug": "hanna",
            "title": "Learning Probabilistic Relational Planning Rules",
            "abstract": "To learn to behave in highly complex domains, agents must represent and learn compact models of the world dynamics. In this paper, we present an algorithm for learning probabilistic STRIPS-like planning operators from examples. We demonstrate the effective learning of rule-based operators for a wide range of traditional planning domains.\n\n",
            "link": "https://people.csail.mit.edu/lpk/papers/pasula-icaps04.pdf",
            "authors": "Pasula, Hanna, Luke S. Zettlemoyer, and Leslie Pack Kaelbling",
            "venue": "ICAPS",
            "sessions": null,
            "year": 2004,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Probabilistic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Fully Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Predicate Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Action Information"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Parameters Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Preconditions",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Effects ",
                    "parent": "Action Information"
                },
                {
                    "name": "State Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Init Access",
                    "parent": "State Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 11,
            "slug": "luke",
            "title": "Learning planning rules in noisy stochastic worlds",
            "abstract": "We present an algorithm for learning a model of the effects of actions in noisy stochastic worlds. We consider learning in a 3D simulated blocks world with realistic physics. To model this world, we develop a planning representation with explicit mechanisms for expressing object reference and noise. We then present a learning algorithm that can create rules while also learning derived predicates, and evaluate this algorithm in the blocks world simulator, demonstrating that we can learn rules that effectively model the world dynamics.\n",
            "link": "https://people.csail.mit.edu/lpk/papers/2005/zpk-aaai05.pdf",
            "authors": "Zettlemoyer, Luke S., Hanna Pasula, and Leslie Pack Kaelbling",
            "venue": "AAAI",
            "sessions": null,
            "year": 2005,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Probabilistic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Fully Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Predicate Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Action Information"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Parameters Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Preconditions",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Effects ",
                    "parent": "Action Information"
                },
                {
                    "name": "State Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Init Access",
                    "parent": "State Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 8,
            "slug": "expo",
            "title": "Learning by Experimentation: Incremental Refinement of Incomplete Planning Domains",
            "abstract": "Building a knowledge base requires iterative refinement to correct imperfections that keep lurking after each new version of the system. This paper concentrates on the automatic refinement of incomplete domain models for planning systems, presenting both a methodology for addressing the problem and empirical results. Planning knowledge may be refined automatically through direct interaction with the environment. Missing conditions cause unreliable predictions of action outcomes. Missing effects cause unreliable predictions of facts about the state. We present a practical approach based on continuous and selective interaction with the environment that pinpoints the type of fault in the domain knowledge that causes any unexpected behavior of the environment, and resorts to experimentation when additional information is needed to correct the fault. Our approach has been implemented in EXPO, a system that uses PRODIGY as a baseline planner and improves its domain knowledge in several domains when initial domain knowledge is up to 50% incomplete. The empirical results presented show that EXPO dramatically improves its prediction accuracy and reduces the amount of unreliable action outcomes.\n\n",
            "link": "https://www.sciencedirect.com/science/article/pii/B9781558603356500192",
            "authors": "Yolanda Gil",
            "venue": "ICML",
            "sessions": null,
            "year": 1994,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Fully Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Predicate Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Action Information"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Parameters Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Preconditions",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Effects ",
                    "parent": "Action Information"
                },
                {
                    "name": "State Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Init Access",
                    "parent": "State Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 14,
            "slug": "slaf",
            "title": "Learning Partially Observable Deterministic Action Models",
            "abstract": "We present exact algorithms for identifying deterministic-actions' effects and preconditions in dynamic partially observable domains. They apply when one does not know the action model (the way actions affect the world) of a domain and must learn it from partial observations over time. Such scenarios are common in real world applications. They are challenging for AI tasks because traditional domain structures that underly tractability (e.g., conditional independence) fail there (e.g., world features become correlated). Our work departs from traditional assumptions about partial observations and action models. In particular, it focuses on problems in which actions are deterministic of simple logical structure and observation models have all features observed with some frequency. We yield tractable algorithms for the modified problem for such domains. Our algorithms take sequences of partial observations over time as input, and output deterministic action models that could have lead to those observations. The algorithms output all or one of those models (depending on our choice), and are exact in that no model is misclassified given the observations. Our algorithms take polynomial time in the number of time steps and state features for some traditional action classes examined in the AI-planning literature, e.g., STRIPS actions. In contrast, traditional approaches for HMMs and Reinforcement Learning are inexact and exponentially intractable for such domains. Our experiments verify the theoretical tractability guarantees, and show that we identify action models exactly. Several applications in planning, autonomous exploration, and adventure-game playing already use these results. They are also promising for probabilistic settings, partially observable reinforcement learning, and diagnosis.\n",
            "link": "https://www.aaai.org/Papers/JAIR/Vol33/JAIR-3310.pdf",
            "authors": "Amir, Eyal, and Allen Chang",
            "venue": "JAIR",
            "sessions": null,
            "year": 2008,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Partially Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Predicate Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 32,
            "slug": "ccn",
            "title": "Bridging the Gap: Providing Post-Hoc Symbolic Explanations for Sequential Decision-Making Problems with Black Box Simulators",
            "abstract": "As increasingly complex AI systems are introduced into our daily lives, it becomes important for such systems to be capable of explaining the rationale for their decisions and allowing users to contest these decisions. A significant hurdle to allowing for such explanatory dialogue could be the vocabulary mismatch between the user and the AI system. This paper introduces methods for providing contrastive explanations in terms of user-specified concepts for sequential decision-making settings where the system's model of the task may be best represented as an inscrutable model. We do this by building partial symbolic models of a local approximation of the task that can be leveraged to answer the user queries. We test these methods on a popular Atari game (Montezuma's Revenge) and variants of Sokoban (a well-known planning benchmark) and report the results of user studies to evaluate whether people find explanations generated in this form useful.\n",
            "link": "https://arxiv.org/abs/2002.01080",
            "authors": "Sreedharan, Sarath, Utkarsh Soni, Mudit Verma, Siddharth Srivastava, and Subbarao Kambhampati",
            "venue": "ICML-WS",
            "sessions": null,
            "year": 2020,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Agent Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Rationality",
                    "parent": "Agent Features"
                },
                {
                    "name": "Optimally Rational",
                    "parent": "Rationality"
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Cost",
                    "parent": "Actions"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Fully Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Cost",
                    "parent": "Action Information"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 21,
            "slug": "tramp",
            "title": "Action-model acquisition for planning via transfer learning",
            "abstract": "Applying learning techniques to acquire action models is an area of intense research interest. Most previous work in this area has assumed that there is a significant amount of training data available in a planning domain of interest. However, it is often difficult to acquire sufficient training data to ensure the learnt action models are of high quality. In this paper, we seek to explore a novel algorithm framework, called TRAMP, to learn action models with limited training data in a target domain, via transferring as much of the available information from other domains (called source domains) as possible to help the learning task, assuming action models in source domains can be transferred to the target domain. TRAMP transfers knowledge from source domains by first building structure mappings between source and target domains, and then exploiting extra knowledge from Web search to bridge and transfer knowledge from sources. Specifically, TRAMP first encodes training data with a set of propositions, and formulates the transferred knowledge as a set of weighted formulas. After that it learns action models for the target domain to best explain the set of propositions and the transferred knowledge. We empirically evaluate TRAMP in different settings to see their advantages and disadvantages in six planning domains, including four International Planning Competition (IPC) domains and two synthetic domains.\n\n",
            "link": "https://www.sciencedirect.com/science/article/pii/S0004370214000320",
            "authors": "Zhuo, Hankz Hankui, and Qiang Yang",
            "venue": "AIJ",
            "sessions": null,
            "year": 2014,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Typing",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Parameters Typed",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Partially Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Predicate Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Typing",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Action Information"
                },
                {
                    "name": "Typing",
                    "parent": "Action Information"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Parameters Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Preconditions",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Effects ",
                    "parent": "Action Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 13,
            "slug": "hanna-luke",
            "title": "Learning Symbolic Models of Stochastic Domains",
            "abstract": "In this article, we work towards the goal of developing agents that can learn to act in complex worlds. We develop a probabilistic, relational planning rule representation that compactly models noisy, nondeterministic action effects, and show how such rules can be effectively learned. Through experiments in simple planning domains and a 3D simulated blocks world with realistic physics, we demonstrate that this learning algorithm allows agents to effectively model world dynamics.\n",
            "link": "https://www.aaai.org/Papers/JAIR/Vol29/JAIR-2910.pdf",
            "authors": "Pasula, Hanna M., Luke S. Zettlemoyer, and Leslie Pack Kaelbling",
            "venue": "JAIR",
            "sessions": null,
            "year": 2007,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Probabilistic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Fully Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Predicate Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Action Information"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Parameters Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Preconditions",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Effects ",
                    "parent": "Action Information"
                },
                {
                    "name": "State Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Init Access",
                    "parent": "State Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 33,
            "slug": "dam",
            "title": "STRIPS Action Discovery",
            "abstract": "The problem of specifying high-level knowledge bases for planning becomes a hard task in realistic environments. This knowledge is usually handcrafted and is hard to keep updated, even for system experts. Recent approaches have shown the success of classical planning at synthesizing action models even when all intermediate states are missing. These approaches can synthesize action schemas in Planning Domain Definition Language (PDDL) from a set of execution traces each consisting, at least, of an initial and final state. In this paper, we propose a new algorithm to unsupervisedly synthesize STRIPS action models with a classical planner when action signatures are unknown. In addition, we contribute with a compilation to classical planning that mitigates the problem of learning static predicates in the action model preconditions, exploits the capabilities of SAT planners with parallel encodings to compute action schemas and validate all instances. Our system is flexible in that it supports the inclusion of partial input information that may speed up the search. We show through several experiments how learned action models generalize over unseen planning instances.\n",
            "link": "https://arxiv.org/abs/2001.11457",
            "authors": "Su\u00e1rez-Hern\u00e1ndez, Alejandro, Javier Segovia-Aguas, Carme Torras, and Guillem Aleny\u00e0",
            "venue": "arXiv",
            "sessions": null,
            "year": 2020,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Typing",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Parameters Typed",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Partially Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Predicate Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Typing",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Preconditions",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Effects ",
                    "parent": "Action Information"
                },
                {
                    "name": "State Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Goal Access",
                    "parent": "State Information"
                },
                {
                    "name": "Init Access",
                    "parent": "State Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 6,
            "slug": "prodigy",
            "title": "Learning by Experimentation: The Operator Refinement Method",
            "abstract": "Autonomous systems require the ability to plan effective courses of action under potentially uncertain or unpredictable contingencies. Planning requires knowledge of the environment that is accurate enough to allow reasoning about actions.  If the environment is too complex or very dynamic, goal-driven learning with reactive feedback becomes a necessity. This chapter addresses the issue of learning by experimentation as an integral component of PRODIGY. PRODIGY is a flexible planning system that encodes its domain knowledge as declarative operators, and applies theoperator refinement methodto acquire additional preconditions or postconditions when observed consequences diverge from internal expectations. When multiple explanations for the observed divergence are consistent with the existing domain knowledge, experiments to discriminate among these explanations are generated. The experimentation process isolates the deficient operator and inserts the discriminant condition or unforeseen side-effect to avoid similar impasses in future planning. Thus, experimentation is demand-driven and exploits both the internal state of the planner and any external feedback received.  A detailed example of integrated experiment formulation in presented as the basis for a systematic approach to extending an incomplete domain theory or correcting a potentially inaccurate one.\n\n",
            "link": "https://kilthub.cmu.edu/articles/journal_contribution/Learning_by_Experimentation_The_Operator_Refinement_Method/6622868/1",
            "authors": "Carbonell, Jaime G., and Yolanda Gil",
            "venue": "MLBook",
            "sessions": null,
            "year": 1990,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Fully Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Predicate Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Preconditions",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Effects ",
                    "parent": "Action Information"
                },
                {
                    "name": "State Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Init Access",
                    "parent": "State Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 27,
            "slug": "louga",
            "title": "LOUGA: Learning Planning Operators Using Genetic Algorithms",
            "abstract": "Planning domain models are critical input to current automated planners. These models provide description of planning operators that formalize how an agent can change the state of the world. It is not easy to obtain accurate description of planning operators, namely to ensure that all preconditions and effects are properly specified. Therefore automated techniques to learn them are important for domain modelling.\n",
            "link": "https://www.springerprofessional.de/en/louga-learning-planning-operators-using-genetic-algorithms/15981308",
            "authors": "Ku\u010dera, Ji\u0159\u00ed, and Roman Bart\u00e1k",
            "venue": "PRKAW",
            "sessions": null,
            "year": 2018,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Typing",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Parameters Typed",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Partially Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Predicate Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Action Information"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Parameters Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Preconditions",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Effects ",
                    "parent": "Action Information"
                },
                {
                    "name": "State Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Init Access",
                    "parent": "State Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Partial",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 43,
            "slug": "dbmps",
            "title": "Initial Results on Generating Macro Actions from a Plan Database for Planning on Autonomous Mobile Robots",
            "abstract": "Planning in an on-line robotics context has the specific requirement of a short planning duration. A property of typical contemporary scenarios is that (mobile) robots perform similar or even repeating tasks during operation. With these robot domains in mind, we propose database-driven macro planning for STRIPS (DBMP/S) that learns macros \u2013 action sequences that frequently appear in plans \u2013 from experience for PDDL-based planners. Planning duration is improved over time by off-line processing of seed plans using a scalable database. The approach is indifferent about the specific planner by representing the resulting macros again as actions with preconditions and effects determined based on the actions contained in the macro. For some domains we have used separate planners for learning and execution exploiting their respective strengths. Initial results based on some IPC domains and a logistic robot scenario show significantly improved (over non-macro planners) or slightly better and comparable (to existing macro planners) performance.\n",
            "link": "https://ojs.aaai.org/index.php/ICAPS/article/view/13868/13717",
            "authors": "Till Hofmann, Tim Niemueller, and Gerhard Lakemeyer\n",
            "venue": "ICAPS",
            "sessions": null,
            "year": 2017,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Typing",
                    "parent": "Actions"
                },
                {
                    "name": "Macros",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Parameters Typed",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Fully Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Predicate Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Typing",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Action Information"
                },
                {
                    "name": "Typing",
                    "parent": "Action Information"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Parameters Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Preconditions",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Effects ",
                    "parent": "Action Information"
                },
                {
                    "name": "State Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Goal Access",
                    "parent": "State Information"
                },
                {
                    "name": "Init Access",
                    "parent": "State Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 16,
            "slug": "opmaker2",
            "title": "Automated acquisition of action knowledge",
            "abstract": "AI planning engines require detailed specifications of dynamic knowledge of the domain in which they are to operate, before they can function. Further, they require domain-specific heuristics before they can function efficiently. The problem of formulating domain models containing dynamic knowledge regarding actions is a barrier to the widespread uptake of AI planning, because of the difficulty in acquiring and maintaining them. Here we postulate a method which inputs a partial domain model (one without knowledge of domain actions) and training solution sequences to planning tasks, and outputs the full domain model, including heuristics that can be used to make plan generation more efficient. To do this we extend GIPO's Opmaker system (Simpson et al., 2007) so that it can induce representations of actions from training sequences without intermediate state information and without requiring large numbers of examples. This method shows the potential for considerably reducing the burden of knowledge engineering, in that it would be possible to embed the method into an autonomous program (agent) which is required to do planning. We illustrate the algorithm as part of an overall method to acquire a planning domain model, and detail results that show the efficacy of the induced model.\n",
            "link": "http://eprints.hud.ac.uk/id/eprint/3292/1/mccluskeyCRC.pdf",
            "authors": "McCluskey, Thomas Leo, S. N. Cresswell, N. Elisabeth Richardson, and Margaret M. West",
            "venue": "ICAART",
            "sessions": null,
            "year": 2009,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Typing",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Parameters Typed",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Unobservable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Predicate Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Typing",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Action Information"
                },
                {
                    "name": "Typing",
                    "parent": "Action Information"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Parameters Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Preconditions",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Effects ",
                    "parent": "Action Information"
                },
                {
                    "name": "State Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Goal Access",
                    "parent": "State Information"
                },
                {
                    "name": "Init Access",
                    "parent": "State Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 23,
            "slug": "nlocm",
            "title": "Domain Model Acquisition in Domains with Action Costs",
            "abstract": "This paper addresses the challenge of automated numeric domain model acquisition from observations. Many industrial and commercial applications of planning technology rely on numeric planning models. For example, in the area of autonomous systems and robotics, an autonomous robot often has to reason about its position in space, power levels and storage capacities. It is essential for these models to be easy to construct. Ideally, they should be automatically constructed. Learning the structure of planning domains from observations of action traces has produced successful results in classical planning. In this work, we present the first results in generalising approaches from classical planning to numeric planning. We restrict the numeric domains to those that include fixed action costs. Taking the finite state automata generated by the LOCM family of algorithms, we learn costs associated with machines; specifically to the object transitions and the state parameters. We learn action costs from action traces (with only the final cost of the plans as extra information) using a constraint programming approach. We demonstrate the effectiveness of this approach on standard benchmarks.\n\n",
            "link": "https://ojs.aaai.org/index.php/ICAPS/article/view/13762",
            "authors": "Gregory, Peter, and Alan Lindsay",
            "venue": "ICAPS",
            "sessions": null,
            "year": 2016,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Typing",
                    "parent": "Actions"
                },
                {
                    "name": "Cost",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Parameters Typed",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Unobservable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Action Information"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Parameters Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Cost",
                    "parent": "Action Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                },
                {
                    "name": "Cost",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 37,
            "slug": "blai-extended",
            "title": "Learning First-Order Representations for Planning from Black-Box States: New Results",
            "abstract": "Recently Bonet and Geffner have shown that first-order representations for planning domains can be learned from the structure of the state space without any prior knowledge about the action schemas or domain predicates. For this, the learning problem is formulated as the search for a simplest first-order domain description D that along with information about instances I_i (number of objects and initial state) determine state space graphs G(P_i) that match the observed state graphs G_i where P_i = (D, I_i). The search is cast and solved approximately by means of a SAT solver that is called over a large family of propositional theories that differ just in the parameters encoding the possible number of action schemas and domain predicates, their arities, and the number of objects. In this work, we push the limits of these learners by moving to an answer set programming (ASP) encoding using the CLINGO system. The new encodings are more transparent and concise, extending the range of possible models while facilitating their exploration. We show that the domains introduced by Bonet and Geffner can be solved more efficiently in the new approach, often optimally, and furthermore, that the approach can be easily extended to handle partial information about the state graphs as well as noise that prevents some states from being distinguished.",
            "link": "https://arxiv.org/abs/2105.10830",
            "authors": "Rodriguez, Ivan D., Blai Bonet, Javier Romero, and Hector Geffner",
            "venue": "arXiv",
            "sessions": null,
            "year": 2021,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Partially Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Unobservable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Noise",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 5,
            "slug": "live",
            "title": "Rule creation and rule learning through environmental exploration\n",
            "abstract": "The task of learning from environment is specified. It requires the learner to infer the laws of the environment in terms of its percepts and actions, and use the laws to solve problems. Based on research on problem space creation and discrimination learning, this paper reports an approach in which exploration, rule creation and rule learning are coordinated in a single framework. With this approach, the system LIVE creates STRIPS-Iike rules by noticing the changes in the environment when actions are taken, and later refines the rules by explaining the failures of their predictions. Unlike many other learning systems, since LIVE treats learning and problem solving as interleaved activities, no training instance nor any concept hierarchy is necessary to start learning. Furthermore, the approach is capable of discovering hidden features from the environment when normal discrimination process fails to make any progress.\n\n",
            "link": "https://www.ijcai.org/Proceedings/89-1/Papers/108.pdf",
            "authors": "Wei-Min Shen and Herbert A. Simon",
            "venue": "IJCAI",
            "sessions": null,
            "year": 1989,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Fully Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "State Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Goal Access",
                    "parent": "State Information"
                },
                {
                    "name": "Init Access",
                    "parent": "State Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 30,
            "slug": "fama",
            "title": "Learning action models with minimal observability",
            "abstract": "This paper presents FAMA, a novel approach for learning Strips action models from observations of plan executions that compiles the learning task into a classical planning task. Unlike all existing learning systems, FAMA is able to learn when the actions of the plan executions are partially or totally unobservable and information on intermediate states is partially provided. This flexibility makes FAMA an ideal learning approach in domains where only sensoring data are accessible. Additionally, we leverage the compilation scheme and extend it to come up with an evaluation method that allows us to assess the quality of a learned model syntactically, that is, with respect to the actual model; and, semantically, that is, with respect to a set of observations of plan executions. We also show that the extended compilation scheme can be used to lay the foundations of a framework for action model comparison. FAMA is exhaustively evaluated over a wide range of IPC domains and its performance is compared to ARMS, a state-of-the-art benchmark in action model learning.\n\n",
            "link": "https://www.sciencedirect.com/science/article/abs/pii/S0004370218304259",
            "authors": "Aineto, Diego, Sergio Jim\u00e9nez Celorrio, and Eva Onaindia",
            "venue": "AIJ",
            "sessions": null,
            "year": 2019,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Partially Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Predicate Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Action Information"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Parameters Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Preconditions",
                    "parent": "Action Information"
                },
                {
                    "name": "Partial Effects ",
                    "parent": "Action Information"
                },
                {
                    "name": "State Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Goal Access",
                    "parent": "State Information"
                },
                {
                    "name": "Init Access",
                    "parent": "State Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Partial",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 22,
            "slug": "dup",
            "title": "Discovering Underlying Plans Based on Distributed Representations of Actions",
            "abstract": "Plan recognition aims to discover target plans (i.e., sequences of actions) behind observed actions, with history plan libraries or domain models in hand. Previous approaches either discover plans by maximally \"matching\" observed actions to plan libraries, assuming target plans are from plan libraries, or infer plans by executing domain models to best explain the observed actions, assuming complete domain models are available. In real world applications, however, target plans are often not from plan libraries and complete domain models are often not available, since building complete sets of plans and complete domain models are often difficult or expensive. In this paper we view plan libraries as corpora and learn vector representations of actions using the corpora; we then discover target plans based on the vector representations. Our approach is capable of discovering underlying plans that are not from plan libraries, without requiring domain models provided. We empirically demonstrate the effectiveness of our approach by comparing its performance to traditional plan recognition approaches in three planning domains.\n\n",
            "link": "http://rakaposhi.eas.asu.edu/aamas16-hankz.pdf",
            "authors": "Tian, Xin, Hankz Hankui Zhuo, and Subbarao Kambhampati",
            "venue": "AAMAS",
            "sessions": null,
            "year": 2016,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Unobservable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 29,
            "slug": "icarus",
            "title": "Learning Planning Operators from Episodic Traces",
            "abstract": "Learning is an important aspect of human intelligence. People learn from various aspects of their experience over time. We present an episodic infrastructure for learning in the context of a cognitive architecture, ICARUS. After a review of this architecture, we formally define the architectural extensions for episodic capabilities. We then demonstrate the extended system\u2019s capability to learn planning operators using the episodic traces from two Minecraft-like scenarios.",
            "link": "https://aaai.org/Papers/Symposia/Spring/2018/SS-2018_Technical_Report_SS-18.pdf#page=577",
            "authors": "M\u00e9nager, David, Dongkyu Choi, Mark Roberts, and David W. Aha",
            "venue": "AAAI-SS",
            "sessions": null,
            "year": 2018,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Fully Observable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Predicate Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicate Information"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Action Information"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Parameters Known",
                    "parent": "Action Information"
                },
                {
                    "name": "State Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Goal Access",
                    "parent": "State Information"
                },
                {
                    "name": "Init Access",
                    "parent": "State Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        },
        {
            "UID": 17,
            "slug": "locm2",
            "title": "Generalised Domain Model Acquisition from Action Traces",
            "abstract": "One approach to the problem of formulating domain models for planning is to learn the models from example action sequences. The LOCM system demonstrated the feasibility of learning domain models from example action sequences only, with no observation of states before, during or after the plans. LOCM uses an object-centred representation, in which each object is represented by a single parameterised state machine. This makes it powerful for learning domains which fit within that representation, but there are some well-known domains which do not. This paper introduces LOCM2, a novel algorithm in which the domain representation of LOCM is generalised to allow multiple parameterised state machines to represent a single object. This extends the coverage of domains for which an adequate domain model can be learned. The LOCM2 algorithm is described and evaluated by testing domain learning from example plans from published results of past International Planning Competitions.",
            "link": "https://ojs.aaai.org/index.php/ICAPS/article/view/13476",
            "authors": "Cresswell, Stephen, and Peter Gregory",
            "venue": "ICAPS",
            "sessions": null,
            "year": 2011,
            "keywords": null,
            "tags": [
                {
                    "name": "Learning Parameters",
                    "parent": null
                },
                {
                    "name": "Model Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Uncertainity ",
                    "parent": "Model Features"
                },
                {
                    "name": "Deterministic",
                    "parent": "Uncertainity "
                },
                {
                    "name": "Actions",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Actions"
                },
                {
                    "name": "Typing",
                    "parent": "Actions"
                },
                {
                    "name": "Predicates",
                    "parent": "Model Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Predicates"
                },
                {
                    "name": "Parameters Typed",
                    "parent": "Predicates"
                },
                {
                    "name": "Data Features",
                    "parent": "Learning Parameters"
                },
                {
                    "name": "Fluent Observability",
                    "parent": "Data Features"
                },
                {
                    "name": "Unobservable",
                    "parent": "Fluent Observability"
                },
                {
                    "name": "Action Information",
                    "parent": "Data Features"
                },
                {
                    "name": "Parameterized",
                    "parent": "Action Information"
                },
                {
                    "name": "Action Labels Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Parameters Known",
                    "parent": "Action Information"
                },
                {
                    "name": "Trace",
                    "parent": "Data Features"
                },
                {
                    "name": "Full",
                    "parent": "Trace"
                }
            ],
            "citations": [],
            "selected": true
        }
    ],
    "links": [
        {
            "source": 11,
            "target": 14
        },
        {
            "source": 11,
            "target": 8
        },
        {
            "source": 11,
            "target": 9
        },
        {
            "source": 11,
            "target": 5
        },
        {
            "source": 13,
            "target": 14
        },
        {
            "source": 45,
            "target": 14
        },
        {
            "source": 45,
            "target": 14
        },
        {
            "source": 45,
            "target": 46
        },
        {
            "source": 10,
            "target": 8
        },
        {
            "source": 9,
            "target": 8
        },
        {
            "source": 9,
            "target": 5
        },
        {
            "source": 9,
            "target": 9
        },
        {
            "source": 9,
            "target": 9
        },
        {
            "source": 33,
            "target": 30
        },
        {
            "source": 33,
            "target": 28
        },
        {
            "source": 33,
            "target": 14
        },
        {
            "source": 37,
            "target": 34
        },
        {
            "source": 37,
            "target": 12
        },
        {
            "source": 19,
            "target": 14
        },
        {
            "source": 19,
            "target": 8
        },
        {
            "source": 19,
            "target": 13
        },
        {
            "source": 19,
            "target": 13
        },
        {
            "source": 28,
            "target": 14
        },
        {
            "source": 28,
            "target": 17
        },
        {
            "source": 28,
            "target": 24
        },
        {
            "source": 28,
            "target": 25
        },
        {
            "source": 28,
            "target": 14
        },
        {
            "source": 28,
            "target": 17
        },
        {
            "source": 42,
            "target": 28
        },
        {
            "source": 42,
            "target": 30
        },
        {
            "source": 42,
            "target": 14
        },
        {
            "source": 42,
            "target": 34
        },
        {
            "source": 42,
            "target": 8
        },
        {
            "source": 42,
            "target": 19
        },
        {
            "source": 42,
            "target": 12
        },
        {
            "source": 42,
            "target": 20
        },
        {
            "source": 42,
            "target": 28
        },
        {
            "source": 42,
            "target": 30
        },
        {
            "source": 42,
            "target": 14
        },
        {
            "source": 42,
            "target": 12
        },
        {
            "source": 42,
            "target": 19
        },
        {
            "source": 14,
            "target": 14
        },
        {
            "source": 29,
            "target": 8
        },
        {
            "source": 29,
            "target": 7
        },
        {
            "source": 29,
            "target": 8
        },
        {
            "source": 38,
            "target": 30
        },
        {
            "source": 38,
            "target": 14
        },
        {
            "source": 38,
            "target": 17
        },
        {
            "source": 48,
            "target": 14
        },
        {
            "source": 48,
            "target": 14
        },
        {
            "source": 36,
            "target": 30
        },
        {
            "source": 36,
            "target": 14
        },
        {
            "source": 36,
            "target": 34
        },
        {
            "source": 36,
            "target": 17
        },
        {
            "source": 36,
            "target": 15
        },
        {
            "source": 36,
            "target": 8
        },
        {
            "source": 36,
            "target": 47
        },
        {
            "source": 36,
            "target": 27
        },
        {
            "source": 36,
            "target": 30
        },
        {
            "source": 36,
            "target": 27
        },
        {
            "source": 47,
            "target": 14
        },
        {
            "source": 47,
            "target": 19
        },
        {
            "source": 47,
            "target": 13
        },
        {
            "source": 47,
            "target": 14
        },
        {
            "source": 47,
            "target": 19
        },
        {
            "source": 46,
            "target": 47
        },
        {
            "source": 46,
            "target": 48
        },
        {
            "source": 30,
            "target": 14
        },
        {
            "source": 30,
            "target": 12
        },
        {
            "source": 30,
            "target": 14
        },
        {
            "source": 30,
            "target": 45
        },
        {
            "source": 40,
            "target": 12
        },
        {
            "source": 40,
            "target": 11
        },
        {
            "source": 40,
            "target": 12
        },
        {
            "source": 17,
            "target": 15
        },
        {
            "source": 17,
            "target": 16
        },
        {
            "source": 22,
            "target": 12
        },
        {
            "source": 15,
            "target": 16
        },
        {
            "source": 15,
            "target": 16
        },
        {
            "source": 44,
            "target": 30
        },
        {
            "source": 44,
            "target": 17
        },
        {
            "source": 26,
            "target": 14
        },
        {
            "source": 26,
            "target": 14
        },
        {
            "source": 24,
            "target": 17
        },
        {
            "source": 24,
            "target": 15
        },
        {
            "source": 24,
            "target": 24
        },
        {
            "source": 24,
            "target": 16
        },
        {
            "source": 24,
            "target": 18
        },
        {
            "source": 24,
            "target": 19
        },
        {
            "source": 24,
            "target": 18
        },
        {
            "source": 24,
            "target": 16
        },
        {
            "source": 20,
            "target": 14
        },
        {
            "source": 20,
            "target": 8
        },
        {
            "source": 20,
            "target": 19
        },
        {
            "source": 20,
            "target": 13
        },
        {
            "source": 20,
            "target": 12
        },
        {
            "source": 20,
            "target": 11
        },
        {
            "source": 20,
            "target": 19
        },
        {
            "source": 20,
            "target": 13
        }
    ]
}